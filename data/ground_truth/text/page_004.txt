Table of Contents
Part I
Item 1. Business
Our Company
NVIDIA pioneered accelerated computing to help solve the most challenging computational problems. NVIDIA is now a full-stack
computing infrastructure company with data-center-scale offerings that are reshaping industry.
Our full-stack includes the foundational CUDA programming model that runs on all NVIDIA GPUs, as well as hundreds of domain-
specific software libraries, software development kits, or SDKs, and Application Programming Interfaces, or APIs. This deep and
broad software stack accelerates the performance and eases the deployment of NVIDIA accelerated computing for computationally
intensive workloads such as artificial intelligence, or AI, model training and inference, data analytics, scientific computing, and 3D
graphics, with vertical-specific optimizations to address industries ranging from healthcare and telecom to automotive and
manufacturing.
Our data-center-scale offerings are comprised of compute and networking solutions that can scale to tens of thousands of GPU-
accelerated servers interconnected to function as a single giant computer; this type of data center architecture and scale is needed
for the development and deployment of modern AI applications.
The GPU was initially used to simulate human imagination, enabling the virtual worlds of video games and films. Today, it also
simulates human intelligence, enabling a deeper understanding of the physical world. Its parallel processing capabilities, supported
by thousands of computing cores, are essential for deep learning algorithms. This form of AI, in which software writes itself by
learning from large amounts of data, can serve as the brain of computers, robots and self-driving cars that can perceive and
understand the world. GPU-powered AI solutions are being developed by thousands of enterprises to deliver services and products
that would have been immensely difficult or even impossible with traditional coding. Examples include generative AI, which can
create new content such as text, code, images, audio, video, and molecule structures, and recommendation systems, which can
recommend highly relevant content such as products, services, media or ads using deep neural networks trained on vast datasets
that capture the user preferences.
NVIDIA has a platform strategy, bringing together hardware, systems, software, algorithms, libraries, and services to create unique
value for the markets we serve. While the computing requirements of these end markets are diverse, we address them with a unified
underlying architecture leveraging our GPUs and networking and software stacks. The programmable nature of our architecture
allows us to support several multi-billion-dollar end markets with the same underlying technology by using a variety of software
stacks developed either internally or by third-party developers and partners. The large and growing number of developers and
installed base across our platforms strengthens our ecosystem and increases the value of our platform to our customers.
Innovation is at our core. We have invested over $45.3 billion in research and development since our inception, yielding inventions
that are essential to modern computing. Our invention of the GPU in 1999 sparked the growth of the PC gaming market and
redefined computer graphics. With our introduction of the CUDA programming model in 2006, we opened the parallel processing
capabilities of our GPU to a broad range of compute-intensive applications, paving the way for the emergence of modern AI. In 2012,
the AlexNet neural network, trained on NVIDIA GPUs, won the ImageNet computer image recognition competition, marking the “Big
Bang” moment of AI. We introduced our first Tensor Core GPU in 2017, built from the ground-up for the new era of AI, and our first
autonomous driving system-on-chips, or SoC, in 2018. Our acquisition of Mellanox in 2020 expanded our innovation canvas to
include networking and led to the introduction of a new processor class – the data processing unit, or DPU. Over the past 5 years,
we have built full software stacks that run on top of our GPUs and CUDA to bring AI to the world’s largest industries, including
NVIDIA DRIVE stack for autonomous driving, Clara for healthcare, and Omniverse for industrial digitalization; and introduced the
NVIDIA AI Enterprise software – essentially an operating system for enterprise AI applications. In 2023, we introduced our first data
center CPU, Grace, built for giant-scale AI and high-performance computing. With a strong engineering culture, we drive fast, yet
harmonized, product and technology innovations in all dimensions of computing including silicon, systems, networking, software and
algorithms. More than half of our engineers work on software.
The world’s leading cloud service providers, or CSPs, and consumer internet companies use our data center-scale accelerated
computing platforms to enable, accelerate or enrich the services they deliver to billions of end users, including AI solutions and
assistants, search, recommendations, social networking, online shopping, live video, and translation.
Enterprises and startups across a broad range of industries use our accelerated computing platforms to build new generative AI-
enabled products and services, or to dramatically accelerate and reduce the costs of their workloads and workflows. The enterprise
software industry uses them for new AI assistants and chatbots; the transportation industry for autonomous driving; the healthcare
industry for accelerated and computer-aided drug discovery; and the financial services industry for customer support and fraud
detection.